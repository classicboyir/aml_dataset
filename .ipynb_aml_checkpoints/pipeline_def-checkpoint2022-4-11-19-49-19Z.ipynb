{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "import azureml.core\r\n",
        "from azureml.core.runconfig import JarLibrary\r\n",
        "from azureml.core.compute import ComputeTarget, DatabricksCompute\r\n",
        "from azureml.exceptions import ComputeTargetException\r\n",
        "from azureml.core import Workspace, Environment, Experiment, Datastore, Dataset, ScriptRunConfig\r\n",
        "from azureml.pipeline.core import Pipeline, PipelineData, TrainingOutput\r\n",
        "from azureml.pipeline.steps import DatabricksStep, PythonScriptStep\r\n",
        "from azureml.core.datastore import Datastore\r\n",
        "from azureml.data.data_reference import DataReference\r\n",
        "# from azureml.pipeline.steps import HyperDriveStep, HyperDriveStepRun, PythonScriptStep\r\n",
        "\r\n",
        "# Check core SDK version number\r\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "SDK version: 1.40.0\n"
        }
      ],
      "execution_count": 476,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\r\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "distributeddeeplearningqmx\ndeep-learning-challenge\nwestus2\n3df1840f-dd4b-4f54-a831-e20536439b3a\n"
        }
      ],
      "execution_count": 477,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "db_compute_name = \"ADBCluster\" # Databricks compute name\r\n",
        "\r\n",
        "databricks_compute = DatabricksCompute(workspace=ws, name=db_compute_name)\r\n",
        "print('Compute target {} already exists'.format(db_compute_name))\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Compute target ADBCluster already exists\n"
        }
      ],
      "execution_count": 479,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import PipelineParameter\r\n",
        "from azureml.pipeline.core.pipeline_output_dataset import PipelineOutputAbstractDataset\r\n",
        "\r\n",
        "def_blob_store = Datastore(ws, \"generalpurposeaccount\")\r\n",
        "print('Datastore {} will be used'.format(def_blob_store.name))\r\n",
        "\r\n",
        "step_1_output = PipelineData(\"output\", datastore=def_blob_store)\r\n",
        "# ds_step_1_output = PipelineOutputAbstractDataset(step_1_output) # .as_dataset()\r\n",
        "ds_step_1_output = step_1_output.as_dataset()\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Datastore generalpurposeaccount will be used\n"
        }
      ],
      "execution_count": 480,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1651693315206
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Dataset\r\n",
        "\r\n",
        "dataset = Dataset.get_by_name(ws, \"titanic_from_parquet\")\r\n",
        "dataset.version"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 481,
          "data": {
            "text/plain": "1"
          },
          "metadata": {}
        }
      ],
      "execution_count": 481,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1651693315846
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_name = \"cpu-cluster-4\"\r\n",
        "compute_target = ComputeTarget(workspace=ws, name=cluster_name)\r\n",
        "\r\n"
      ],
      "outputs": [],
      "execution_count": 296,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source_directory = \"./scripts\"\r\n",
        "\r\n",
        "databricks_script_name = \"adb_run.py\"\r\n",
        "aml_script_name = 'aml_run.py'\r\n",
        "\r\n",
        "feature_dataset_name = \"feature_titanic\""
      ],
      "outputs": [],
      "execution_count": 484,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "dbNbStep = DatabricksStep(\r\n",
        "    name=\"ADBFeatureEng\",\r\n",
        "    outputs=[ds_step_1_output],\r\n",
        "    compute_target=databricks_compute,\r\n",
        "    existing_cluster_id=\"0511-174324-3ryh30vo\", # \"0319-164126-ptv2xehc\",\r\n",
        "    python_script_params=[\"--feature_set_1\", \"titanic_1\",\r\n",
        "                          \"--feature_set_2\", \"titanic_2\",\r\n",
        "                          \"--feature_set_3\", \"titanic_3\",\r\n",
        "                          '--output_datastore_name', def_blob_store.name,\r\n",
        "                          \"--output_feature_set_name\", feature_dataset_name],\r\n",
        "    permit_cluster_restart=True,\r\n",
        "    python_script_name=databricks_script_name,\r\n",
        "    source_directory=source_directory,\r\n",
        "    run_name='ADB_Feature_Eng',\r\n",
        "    allow_reuse=False\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 490,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1651694246481
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.runconfig import RunConfiguration\r\n",
        "from azureml.core.conda_dependencies import CondaDependencies\r\n",
        "\r\n",
        "# tf_env = Environment.get(ws, name='AzureML-lightgbm-3.2-ubuntu18.04-py37-cpu')\r\n",
        "# tf_env_c = tf_env.clone(\"deltalake\")\r\n",
        "\r\n",
        "tf_env_c = Environment('deltalake')\r\n",
        "\r\n",
        "conda_dep = CondaDependencies()\r\n",
        "\r\n",
        "conda_dep.add_pip_package(\"sklearn\")\r\n",
        "conda_dep.add_pip_package(\"deltalake\")\r\n",
        "conda_dep.remove_pip_package('azureml-defaults')\r\n",
        "conda_dep.add_pip_package('azureml-core')\r\n",
        "conda_dep.add_pip_package('pandas')\r\n",
        "\r\n",
        "# Adds dependencies to PythonSection of myenv\r\n",
        "tf_env_c.python.conda_dependencies=conda_dep\r\n",
        "\r\n",
        "tf_env_c = tf_env_c.register(workspace=ws)\r\n",
        "\r\n",
        "rcfg = RunConfiguration()\r\n",
        "rcfg.environment = tf_env_c"
      ],
      "outputs": [],
      "execution_count": 491,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ds_step_1_output = step_1_output.as_dataset()\r\n",
        "# mnt_ds_step_1_output = ds_step_1_output.as_mount()\r\n",
        "\r\n",
        "aml_step = PythonScriptStep(script_name=aml_script_name,\r\n",
        "                                       name=\"AML Train\",\r\n",
        "                                       source_directory=source_directory,\r\n",
        "                                       inputs=[ds_step_1_output],\r\n",
        "                                       compute_target=compute_target,\r\n",
        "                                       arguments=['--data_folder', ds_step_1_output,\r\n",
        "                                                  '--featureset_name', feature_dataset_name,\r\n",
        "                                                  '--model_name', 'titanic_model'],\r\n",
        "                                       allow_reuse=False,\r\n",
        "                                       runconfig=rcfg)\r\n"
      ],
      "outputs": [],
      "execution_count": 492,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "steps = [aml_step]\r\n",
        "pipeline = Pipeline(workspace=ws, steps=steps)\r\n",
        "pipeline_run = Experiment(ws, 'DB_FeatureStore').submit(pipeline)\r\n",
        "# pipeline_run.wait_for_completion()\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Created step AML Train [b2f2ec12][b1c339e0-7551-46c5-ba9e-fb4e8c0065a7], (This step will run and generate new outputs)Created step ADBFeatureEng [b0d56823][4e9d3e14-f965-4432-b74a-f2d31bfc8a2f], (This step will run and generate new outputs)\n\nSubmitted PipelineRun 3e26e040-4dfe-4bf7-aa88-048e1aa5961b\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/3e26e040-4dfe-4bf7-aa88-048e1aa5961b?wsid=/subscriptions/3df1840f-dd4b-4f54-a831-e20536439b3a/resourcegroups/deep-learning-challenge/workspaces/distributeddeeplearningqmx&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n"
        }
      ],
      "execution_count": 493,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1651694252978
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_run"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 436,
          "data": {
            "text/plain": "Run(Experiment: DB_FeatureStore,\nId: fbdec19e-8057-4f7e-b8d8-f4d9ee2e21b9,\nType: azureml.PipelineRun,\nStatus: Preparing)",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>DB_FeatureStore</td><td>fbdec19e-8057-4f7e-b8d8-f4d9ee2e21b9</td><td>azureml.PipelineRun</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/fbdec19e-8057-4f7e-b8d8-f4d9ee2e21b9?wsid=/subscriptions/3df1840f-dd4b-4f54-a831-e20536439b3a/resourcegroups/deep-learning-challenge/workspaces/distributeddeeplearningqmx&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 436,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Model\r\n",
        "\r\n",
        "model = Model(ws, name='titanic_model')\r\n",
        "model"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 469,
          "data": {
            "text/plain": "Model(workspace=Workspace.create(name='distributeddeeplearningqmx', subscription_id='3df1840f-dd4b-4f54-a831-e20536439b3a', resource_group='deep-learning-challenge'), name=titanic_model, id=titanic_model:11, version=11, tags={'run_id': '4c52ccc3-761c-444e-a029-dfcb96a645c6'}, properties={})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 469,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_datasets = model.datasets\r\n",
        "input_dataset = model_datasets['featurized data'][0]"
      ],
      "outputs": [],
      "execution_count": 470,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dataset.tags['dtypes']"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 471,
          "data": {
            "text/plain": "\"{'PassengerId': 'int64', 'Survived': 'int64', 'Pclass': 'int64', 'Sex': 'int64', 'Age': 'float64', 'SibSp': 'int64', 'Parch': 'int64', 'Fare': 'float64', 'id': 'object'}\""
          },
          "metadata": {}
        }
      ],
      "execution_count": 471,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf = input_dataset.to_pandas_dataframe()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Dataset.get_by_name"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python38-azureml"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}