{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "import azureml.core\r\n",
        "from azureml.core.runconfig import JarLibrary\r\n",
        "from azureml.core.compute import ComputeTarget, DatabricksCompute\r\n",
        "from azureml.exceptions import ComputeTargetException\r\n",
        "from azureml.core import Workspace, Environment, Experiment, Datastore, Dataset, ScriptRunConfig\r\n",
        "from azureml.pipeline.core import Pipeline, PipelineData, TrainingOutput\r\n",
        "from azureml.pipeline.steps import DatabricksStep, PythonScriptStep\r\n",
        "from azureml.core.datastore import Datastore\r\n",
        "from azureml.data.data_reference import DataReference\r\n",
        "# from azureml.pipeline.steps import HyperDriveStep, HyperDriveStepRun, PythonScriptStep\r\n",
        "\r\n",
        "# Check core SDK version number\r\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "SDK version: 1.40.0\n"
        }
      ],
      "execution_count": 163,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\r\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "distributeddeeplearningqmx\ndeep-learning-challenge\nwestus2\n3df1840f-dd4b-4f54-a831-e20536439b3a\n"
        }
      ],
      "execution_count": 164,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "db_compute_name = \"ADBCluster\" # Databricks compute name\r\n",
        "\r\n",
        "databricks_compute = DatabricksCompute(workspace=ws, name=db_compute_name)\r\n",
        "print('Compute target {} already exists'.format(db_compute_name))\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Compute target ADBCluster already exists\n"
        }
      ],
      "execution_count": 166,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import PipelineParameter\r\n",
        "from azureml.pipeline.core.pipeline_output_dataset import PipelineOutputAbstractDataset\r\n",
        "\r\n",
        "def_blob_store = Datastore(ws, \"generalpurposeaccount\")\r\n",
        "print('Datastore {} will be used'.format(def_blob_store.name))\r\n",
        "\r\n",
        "step_1_output = PipelineData(\"output\", datastore=def_blob_store)\r\n",
        "# ds_step_1_output = PipelineOutputAbstractDataset(step_1_output) # .as_dataset()\r\n",
        "ds_step_1_output = step_1_output.as_dataset()\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Datastore generalpurposeaccount will be used\n"
        }
      ],
      "execution_count": 305,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1651693315206
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Dataset\r\n",
        "\r\n",
        "dataset = Dataset.get_by_name(ws, \"titanic_from_parquet\")\r\n",
        "dataset.version"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 294,
          "data": {
            "text/plain": "1"
          },
          "metadata": {}
        }
      ],
      "execution_count": 294,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1651693315846
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_name = \"cpu-cluster-4\"\r\n",
        "compute_target = ComputeTarget(workspace=ws, name=cluster_name)\r\n",
        "\r\n"
      ],
      "outputs": [],
      "execution_count": 296,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "python_script_name = \"adb_run_delta.py\"\r\n",
        "source_directory = \"./scripts\"\r\n",
        "\r\n",
        "feature_dataset_name = \"feature_titanic\"\r\n",
        "\r\n",
        "dbNbStep = DatabricksStep(\r\n",
        "    name=\"ADBFeatureEng\",\r\n",
        "    outputs=[ds_step_1_output],\r\n",
        "    compute_target=databricks_compute,\r\n",
        "    existing_cluster_id=\"0319-164126-ptv2xehc\",\r\n",
        "    python_script_params=[\"--feature_set_1\", \"titanic_from_parquet\",\r\n",
        "                          \"--feature_set_2\", \"titanic_from_parquet\",\r\n",
        "                          \"--feature_set_3\", \"titanic_from_parquet\",\r\n",
        "                          '--output_datastore_name', def_blob_store.name,\r\n",
        "                          \"--output_feature_set_name\", feature_dataset_name],\r\n",
        "    permit_cluster_restart=True,\r\n",
        "    python_script_name=python_script_name,\r\n",
        "    source_directory=source_directory,\r\n",
        "    run_name='ADB_Feature_Eng',\r\n",
        "    allow_reuse=True\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 328,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1651694246481
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.runconfig import RunConfiguration\r\n",
        "from azureml.core.conda_dependencies import CondaDependencies\r\n",
        "\r\n",
        "# tf_env = Environment.get(ws, name='AzureML-lightgbm-3.2-ubuntu18.04-py37-cpu')\r\n",
        "# tf_env_c = tf_env.clone(\"deltalake\")\r\n",
        "\r\n",
        "tf_env_c = Environment('deltalake')\r\n",
        "\r\n",
        "conda_dep = CondaDependencies()\r\n",
        "\r\n",
        "conda_dep.add_pip_package(\"sklearn\")\r\n",
        "conda_dep.add_pip_package(\"deltalake\")\r\n",
        "conda_dep.remove_pip_package('azureml-defaults')\r\n",
        "conda_dep.add_pip_package('azureml-core')\r\n",
        "conda_dep.add_pip_package('pandas')\r\n",
        "\r\n",
        "# Adds dependencies to PythonSection of myenv\r\n",
        "tf_env_c.python.conda_dependencies=conda_dep\r\n",
        "\r\n",
        "tf_env_c = tf_env_c.register(workspace=ws)\r\n",
        "\r\n",
        "rcfg = RunConfiguration()\r\n",
        "rcfg.environment = tf_env_c"
      ],
      "outputs": [],
      "execution_count": 329,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ds_step_1_output = step_1_output.as_dataset()\r\n",
        "# mnt_ds_step_1_output = ds_step_1_output.as_mount()\r\n",
        "\r\n",
        "aml_step = PythonScriptStep(script_name='aml_run_delta.py',\r\n",
        "                                       name=\"AML Train\",\r\n",
        "                                       source_directory=source_directory,\r\n",
        "                                       inputs=[ds_step_1_output.as_named_input('titanic_ds')],\r\n",
        "                                       compute_target=compute_target,\r\n",
        "                                       arguments=['--data_folder', ds_step_1_output,\r\n",
        "                                                  '--featureset_name', feature_dataset_name,\r\n",
        "                                                  '--model_name', 'titanic_model'],\r\n",
        "                                       allow_reuse=False,\r\n",
        "                                       runconfig=rcfg)\r\n"
      ],
      "outputs": [],
      "execution_count": 330,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "steps = [aml_step]\r\n",
        "pipeline = Pipeline(workspace=ws, steps=steps)\r\n",
        "pipeline_run = Experiment(ws, 'DB_FeatureStore').submit(pipeline)\r\n",
        "# pipeline_run.wait_for_completion()\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Created step AML Train [36dfaf6e][dc617fb1-85d0-4c21-ba8f-a3958df0a0e6], (This step will run and generate new outputs)\nCreated step ADBFeatureEng [bbfb6f77][ee93fe60-1311-430b-9ca9-18a285366b92], (This step will run and generate new outputs)\nSubmitted PipelineRun d94b4bd3-8a8c-46ce-b746-9e3a5da1eb11\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/d94b4bd3-8a8c-46ce-b746-9e3a5da1eb11?wsid=/subscriptions/3df1840f-dd4b-4f54-a831-e20536439b3a/resourcegroups/deep-learning-challenge/workspaces/distributeddeeplearningqmx&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n"
        }
      ],
      "execution_count": 320,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1651694252978
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_run"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 175,
          "data": {
            "text/plain": "Run(Experiment: DB_FeatureStore,\nId: ce654450-796a-4696-b69c-5c8d79b80d04,\nType: azureml.PipelineRun,\nStatus: Preparing)",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>DB_FeatureStore</td><td>ce654450-796a-4696-b69c-5c8d79b80d04</td><td>azureml.PipelineRun</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/ce654450-796a-4696-b69c-5c8d79b80d04?wsid=/subscriptions/3df1840f-dd4b-4f54-a831-e20536439b3a/resourcegroups/deep-learning-challenge/workspaces/distributeddeeplearningqmx&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 175,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data import OutputFileDatasetConfig\r\n",
        "\r\n",
        "step1_output_data = OutputFileDatasetConfig(name=\"processed_data\", destination=(def_blob_store, \"mypath/{run-id}/{output-name}\")).register_on_complete(name='processed_data', \r\n",
        "                                                         description = 'files from step1').as_upload()"
      ],
      "outputs": [],
      "execution_count": 331,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data import OutputFileDatasetConfig\r\n",
        "from azureml.pipeline.steps import PythonScriptStep\r\n",
        "\r\n",
        "prepped_data_path = OutputFileDatasetConfig(name=\"output_path\").register_on_complete(name='processed_data', description = 'files from step1')\r\n",
        "\r\n",
        "aml_step = PythonScriptStep(script_name='aml_run_delta_automl_prep.py',\r\n",
        "                                       name=\"AML Register Data\",\r\n",
        "                                       source_directory=source_directory,\r\n",
        "                                       inputs=[ds_step_1_output],\r\n",
        "                                       outputs=[prepped_data_path],\r\n",
        "                                       compute_target=compute_target,\r\n",
        "                                       arguments=[\"--output_path\", prepped_data_path,\r\n",
        "                                                  '--data_folder', ds_step_1_output],\r\n",
        "                                       allow_reuse=False,\r\n",
        "                                       runconfig=rcfg)"
      ],
      "outputs": [],
      "execution_count": 348,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.automl import AutoMLConfig\r\n",
        "from azureml.pipeline.steps import AutoMLStep\r\n",
        "\r\n",
        "automl_settings = {\r\n",
        "    \"experiment_timeout_minutes\": 20,\r\n",
        "    \"max_concurrent_iterations\": 4,\r\n",
        "    \"primary_metric\" : 'AUC_weighted'\r\n",
        "}\r\n",
        "automl_config = AutoMLConfig(compute_target=compute_target,\r\n",
        "                             task = \"classification\",\r\n",
        "                             training_data=prepped_data_path.read_delimited_files(),\r\n",
        "                             label_column_name=\"Survived\",   \r\n",
        "                             path = source_directory,\r\n",
        "                             enable_early_stopping= True,\r\n",
        "                             featurization= 'auto',\r\n",
        "                             debug_log = \"automl_errors.log\",\r\n",
        "                             **automl_settings\r\n",
        "                            )"
      ],
      "outputs": [],
      "execution_count": 350,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import PipelineData, TrainingOutput\r\n",
        "\r\n",
        "ds = ws.get_default_datastore()\r\n",
        "metrics_output_name = 'metrics_output'\r\n",
        "best_model_output_name = 'best_model_output'\r\n",
        "\r\n",
        "metrics_data = PipelineData(name='metrics_data',\r\n",
        "                           datastore=ds,\r\n",
        "                           pipeline_output_name=metrics_output_name,\r\n",
        "                           training_output=TrainingOutput(type='Metrics'))\r\n",
        "model_data = PipelineData(name='model_data',\r\n",
        "                           datastore=ds,\r\n",
        "                           pipeline_output_name=best_model_output_name,\r\n",
        "                           training_output=TrainingOutput(type='Model'))\r\n"
      ],
      "outputs": [],
      "execution_count": 351,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "automl_train_step = AutoMLStep(name='AutoML_Classification',\r\n",
        "                        automl_config=automl_config,\r\n",
        "                        passthru_automl_config=False,\r\n",
        "                        enable_default_model_output=False,\r\n",
        "                        enable_default_metrics_output=False,\r\n",
        "                        allow_reuse=True)"
      ],
      "outputs": [],
      "execution_count": 352,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "steps = [aml_step]\r\n",
        "pipeline = Pipeline(workspace=ws, steps=steps)\r\n",
        "pipeline_run = Experiment(ws, 'DB_FeatureStore_AutoML').submit(pipeline)\r\n",
        "# pipeline_run.wait_for_completion()\r\n",
        "\r\n",
        "pipeline_run"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Created step AML Train [97ed61d9][ffe429aa-efe6-43cd-9bbe-72e9761bdbb9], (This step will run and generate new outputs)\nCreated step ADBFeatureEng [6ce64d95][3745b17c-ac07-43c3-ad08-ae8269bb45cf], (This step is eligible to reuse a previous run's output)\nSubmitted PipelineRun 8aeb160e-3e38-4a8f-be15-b25e08c8baa6\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/8aeb160e-3e38-4a8f-be15-b25e08c8baa6?wsid=/subscriptions/3df1840f-dd4b-4f54-a831-e20536439b3a/resourcegroups/deep-learning-challenge/workspaces/distributeddeeplearningqmx&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 354,
          "data": {
            "text/plain": "Run(Experiment: DB_FeatureStore_AutoML,\nId: 8aeb160e-3e38-4a8f-be15-b25e08c8baa6,\nType: azureml.PipelineRun,\nStatus: Preparing)",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>DB_FeatureStore_AutoML</td><td>8aeb160e-3e38-4a8f-be15-b25e08c8baa6</td><td>azureml.PipelineRun</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/8aeb160e-3e38-4a8f-be15-b25e08c8baa6?wsid=/subscriptions/3df1840f-dd4b-4f54-a831-e20536439b3a/resourcegroups/deep-learning-challenge/workspaces/distributeddeeplearningqmx&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 354,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python38-azureml"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}