{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import azureml.core\n",
        "import pandas as pd\n",
        "from azureml.core.runconfig import JarLibrary\n",
        "from azureml.core.compute import ComputeTarget, DatabricksCompute\n",
        "from azureml.exceptions import ComputeTargetException\n",
        "from azureml.core import Workspace, Environment, Experiment, Datastore, Dataset, ScriptRunConfig\n",
        "from azureml.pipeline.core import Pipeline, PipelineData, TrainingOutput\n",
        "from azureml.pipeline.steps import DatabricksStep, PythonScriptStep\n",
        "from azureml.core.datastore import Datastore\n",
        "from azureml.data.data_reference import DataReference\n",
        "# from azureml.pipeline.steps import HyperDriveStep, HyperDriveStepRun, PythonScriptStep\n",
        "\n",
        "# Check core SDK version number\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "SDK version: 1.40.0\n"
        }
      ],
      "execution_count": 31,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "distributeddeeplearningqmx\ndeep-learning-challenge\nwestus2\n3df1840f-dd4b-4f54-a831-e20536439b3a\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "db_compute_name = \"ADBCluster\" # Databricks compute name\n",
        "\n",
        "databricks_compute = DatabricksCompute(workspace=ws, name=db_compute_name)\n",
        "print('Compute target {} already exists'.format(db_compute_name))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Compute target ADBCluster already exists\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import PipelineParameter\r\n",
        "from azureml.pipeline.core.pipeline_output_dataset import PipelineOutputAbstractDataset\r\n",
        "\r\n",
        "def_blob_store = Datastore(ws, \"generalpurposeaccount\")\r\n",
        "print('Datastore {} will be used'.format(def_blob_store.name))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def register_dataset(datastore, dataset_name):\r\n",
        "    remote_path = f'dataset-demo/{dataset_name}/'\r\n",
        "    local_path = './data/titanic.csv'\r\n",
        "    datastore.upload_files(files = [local_path],\r\n",
        "                       target_path = remote_path,\r\n",
        "                       overwrite = True,\r\n",
        "                       show_progress = True)\r\n",
        "    \r\n",
        "    dataset = Dataset.Tabular.from_delimited_files(path = [(datastore, remote_path)])\r\n",
        "\r\n",
        "    # preview the first 3 rows of the dataset\r\n",
        "    dataset.take(3).to_pandas_dataframe()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_titanic2 = pd.read_csv('data/titanic.csv')"
      ],
      "outputs": [],
      "execution_count": 32,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set(pdf_titanic.columns) == set(pdf_titanic2.columns)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 34,
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ],
      "execution_count": 34,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "step_1_output = PipelineData(\"output\", datastore=def_blob_store)\n",
        "# ds_step_1_output = PipelineOutputAbstractDataset(step_1_output) # .as_dataset()\n",
        "ds_step_1_output = step_1_output.as_dataset()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Datastore generalpurposeaccount will be used\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1651693315206
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Dataset\n",
        "\n",
        "dataset = Dataset.get_by_name(ws, \"titanic_from_parquet\")\n",
        "val = str(dataset)\n",
        "val"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 27,
          "data": {
            "text/plain": "'TabularDataset\\n{\\n  \"source\": [\\n    \"(\\'generalpurposeaccount\\', \\'titanic_test.parquet/*.parquet\\')\"\\n  ],\\n  \"definition\": [\\n    \"GetDatastoreFiles\",\\n    \"ReadParquetFile\",\\n    \"DropColumns\"\\n  ],\\n  \"registration\": {\\n    \"id\": \"a4e1a4c0-09b3-4d90-bfd4-74d124553bc3\",\\n    \"name\": \"titanic_from_parquet\",\\n    \"version\": 1,\\n    \"workspace\": \"Workspace.create(name=\\'distributeddeeplearningqmx\\', subscription_id=\\'3df1840f-dd4b-4f54-a831-e20536439b3a\\', resource_group=\\'deep-learning-challenge\\')\"\\n  }\\n}'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1651693315846
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 28,
          "data": {
            "text/plain": "{\n  \"source\": [\n    \"('generalpurposeaccount', 'titanic_test.parquet/*.parquet')\"\n  ],\n  \"definition\": [\n    \"GetDatastoreFiles\",\n    \"ReadParquetFile\",\n    \"DropColumns\"\n  ],\n  \"registration\": {\n    \"id\": \"a4e1a4c0-09b3-4d90-bfd4-74d124553bc3\",\n    \"name\": \"titanic_from_parquet\",\n    \"version\": 1,\n    \"workspace\": \"Workspace.create(name='distributeddeeplearningqmx', subscription_id='3df1840f-dd4b-4f54-a831-e20536439b3a', resource_group='deep-learning-challenge')\"\n  }\n}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\r\n",
        "dict1 = {}\r\n",
        "jval = json.loads(val)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "JSONDecodeError",
          "evalue": "Expecting value: line 1 column 1 (char 0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-85a0d0aaa439>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdict1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mjval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
          ]
        }
      ],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.s"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'TabularDataset' object has no attribute 'source'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-6005d6eb3788>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'TabularDataset' object has no attribute 'source'"
          ]
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a."
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_name = \"cpu-cluster-4\"\n",
        "compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 296,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source_directory = \"./scripts\"\n",
        "\n",
        "databricks_script_name = \"adb_run.py\"\n",
        "aml_script_name = 'aml_run.py'\n",
        "\n",
        "feature_dataset_name = \"feature_titanic\""
      ],
      "outputs": [],
      "execution_count": 503,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dbNbStep = DatabricksStep(\n",
        "    name=\"ADBFeatureEng\",\n",
        "    outputs=[ds_step_1_output],\n",
        "    compute_target=databricks_compute,\n",
        "    existing_cluster_id=\"0511-174324-3ryh30vo\", # \"0319-164126-ptv2xehc\",\n",
        "    python_script_params=[\"--feature_set_1\", \"titanic_1\",\n",
        "                          \"--feature_set_2\", \"titanic_2\",\n",
        "                          \"--feature_set_3\", \"titanic_3\",\n",
        "                          '--output_datastore_name', def_blob_store.name,\n",
        "                          \"--output_feature_set_name\", feature_dataset_name],\n",
        "    permit_cluster_restart=True,\n",
        "    python_script_name=databricks_script_name,\n",
        "    source_directory=source_directory,\n",
        "    run_name='ADB_Feature_Eng',\n",
        "    allow_reuse=False\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 504,
      "metadata": {
        "gather": {
          "logged": 1651694246481
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.runconfig import RunConfiguration\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "# tf_env = Environment.get(ws, name='AzureML-lightgbm-3.2-ubuntu18.04-py37-cpu')\n",
        "# tf_env_c = tf_env.clone(\"deltalake\")\n",
        "\n",
        "tf_env_c = Environment('deltalake')\n",
        "\n",
        "conda_dep = CondaDependencies()\n",
        "\n",
        "conda_dep.add_pip_package(\"sklearn\")\n",
        "conda_dep.add_pip_package(\"deltalake\")\n",
        "conda_dep.remove_pip_package('azureml-defaults')\n",
        "conda_dep.add_pip_package('azureml-core')\n",
        "conda_dep.add_pip_package('pandas')\n",
        "\n",
        "# Adds dependencies to PythonSection of myenv\n",
        "tf_env_c.python.conda_dependencies=conda_dep\n",
        "\n",
        "tf_env_c = tf_env_c.register(workspace=ws)\n",
        "\n",
        "rcfg = RunConfiguration()\n",
        "rcfg.environment = tf_env_c"
      ],
      "outputs": [],
      "execution_count": 505,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ds_step_1_output = step_1_output.as_dataset()\n",
        "# mnt_ds_step_1_output = ds_step_1_output.as_mount()\n",
        "\n",
        "aml_step = PythonScriptStep(script_name=aml_script_name,\n",
        "                                       name=\"AML Train\",\n",
        "                                       source_directory=source_directory,\n",
        "                                       inputs=[ds_step_1_output],\n",
        "                                       compute_target=compute_target,\n",
        "                                       arguments=['--data_folder', ds_step_1_output,\n",
        "                                                  '--featureset_name', feature_dataset_name,\n",
        "                                                  '--model_name', 'titanic_model'],\n",
        "                                       allow_reuse=False,\n",
        "                                       runconfig=rcfg)\n"
      ],
      "outputs": [],
      "execution_count": 506,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "steps = [aml_step]\n",
        "pipeline = Pipeline(workspace=ws, steps=steps)\n",
        "pipeline_run = Experiment(ws, 'DB_FeatureStore').submit(pipeline)\n",
        "# pipeline_run.wait_for_completion()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Created step AML Train [1a7a72f2][13860bb5-d3da-4632-bf19-cdde17a53639], (This step will run and generate new outputs)Created step ADBFeatureEng [c24ba9e1][514f39a0-4824-42fd-8ca5-27526faf444c], (This step will run and generate new outputs)\n\nSubmitted PipelineRun fffafab7-23dc-4063-8655-1a1ac830723c\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/fffafab7-23dc-4063-8655-1a1ac830723c?wsid=/subscriptions/3df1840f-dd4b-4f54-a831-e20536439b3a/resourcegroups/deep-learning-challenge/workspaces/distributeddeeplearningqmx&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n"
        }
      ],
      "execution_count": 507,
      "metadata": {
        "gather": {
          "logged": 1651694252978
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_run"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 436,
          "data": {
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>DB_FeatureStore</td><td>fbdec19e-8057-4f7e-b8d8-f4d9ee2e21b9</td><td>azureml.PipelineRun</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/fbdec19e-8057-4f7e-b8d8-f4d9ee2e21b9?wsid=/subscriptions/3df1840f-dd4b-4f54-a831-e20536439b3a/resourcegroups/deep-learning-challenge/workspaces/distributeddeeplearningqmx&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>",
            "text/plain": "Run(Experiment: DB_FeatureStore,\nId: fbdec19e-8057-4f7e-b8d8-f4d9ee2e21b9,\nType: azureml.PipelineRun,\nStatus: Preparing)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 436,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Model\n",
        "\n",
        "model = Model(ws, name='titanic_model')\n",
        "model"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 499,
          "data": {
            "text/plain": "Model(workspace=Workspace.create(name='distributeddeeplearningqmx', subscription_id='3df1840f-dd4b-4f54-a831-e20536439b3a', resource_group='deep-learning-challenge'), name=titanic_model, id=titanic_model:14, version=14, tags={'run_id': '47a6dcba-d2ec-47f2-8b78-bc48a05d6393'}, properties={})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 499,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_datasets = model.datasets\n",
        "input_dataset = model_datasets['features'][0]"
      ],
      "outputs": [],
      "execution_count": 500,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dataset.tags"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 502,
          "data": {
            "text/plain": "{'input_datasets': \"['titanic_1: 1', 'titanic_2: 1', 'titanic_3: 1']\",\n 'regisitered_at': '2022-05-11 20:20:23',\n 'delta_feature_name': 'features.feature_titanic',\n 'run_id': '47a6dcba-d2ec-47f2-8b78-bc48a05d6393',\n 'dtypes': \"{'PassengerId': 'int64', 'Survived': 'int64', 'Pclass': 'int64', 'Sex': 'int64', 'Age': 'float64', 'SibSp': 'int64', 'Parch': 'int64', 'Fare': 'float64', 'id': 'object'}\"}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 502,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf = input_dataset.to_pandas_dataframe()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Dataset.get_by_name"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}